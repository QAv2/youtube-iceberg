<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>An Overview of the Operations in Geometric Algebra â€” Iceberg Archive</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <nav><a href="../index.html">&larr; Back to index</a></nav>

    <article>
        <h1>An Overview of the Operations in Geometric Algebra</h1>
        <div class="meta">
            <span>Channel: sudgylacmoe</span>
            <span>Published: 2023-04-20</span>
            <span>6,837 words</span>
            <span>Source: auto_caption</span>
        </div>
        <div class="tag-pills"><a href="../categories/advanced-mathematics-geometric-physics.html" class="tag-pill">Advanced Mathematics &amp; Geometric Physics</a></div>

        <div class="embed">
            <iframe width="560" height="315"
                src="https://www.youtube-nocookie.com/embed/2AKt6adG_OI"
                frameborder="0" allowfullscreen></iframe>
        </div>

        <div class="transcript">
            <h2>Transcript</h2>
            <p>in geometric algebra there are many different operations that we use while I&#x27;ve mentioned many of them on this channel I haven&#x27;t gone into too much detail on most of them there are also operations that I have just never mentioned before such as the regressive product or grade projection while I&#x27;m going to be covering all of these operations in from zero to Geo eventually I thought it might be nice to have a video that gives a quick description of them all that can be used as a reference another issue that I want to deal with is that my previous explanations of most of these operations have mostly relied on vectors being arrows which is not always the case you can do geometric algebra on linear spaces other than the linear space of arrows and this leads us to the other flavors of geometric algebra the flavor that most of my videos have used is VGA where we start with vectors being arrows but in PGA a vector can be a plane and in CGA a vector can be a circle if we truly want to understand all of these operations we need to understand them in a flavor agnostic way while doing this is necessarily more abstract it makes moving to other flavors much smoother to understand these operations in any flavor of geometric algebra we need to understand how to think of multi-vectors in general terms as well so let&#x27;s start there to understand multi-vectors we need to understand the things that make them up like vectors by vectors Tri vectors Etc when working in a particular flavor we often know what a vector represents so let&#x27;s start with trying to find an abstract understanding of bi-vectors in VGA we think of a bi-vector as an oriented plane segment but really we shouldn&#x27;t think of the bifector as being this particular parallelogram since there are different plane segments that represent the same bi-vector in the end the important thing about this bi-vector is the plane itself and not any particular segment of the plane bi-vectors do still have an orientation and a magnitude but it&#x27;s often useful to consider those as being separate from the plane itself thus we can say that a bifector is a plane with an orientation and a magnitude now one issue with this characterization is that saying that a bi Vector represents a plane is particular to VGA however remember that a plane is simply a two-dimensional Subspace the idea of a two-dimensional Subspace is more abstract and applies to more settings than VGA so if we switch to thinking of bi-vectors as two-dimensional subspaces with an orientation and magnitude we can start to understand by vectors in general in fact we can often get away with generalizing this even further while the orientation and magnitude are important it turns out that we can often forget about them when we are conceptualizing bi-vectors thus we can just think of bi-vectors as representing two-dimensional subspaces it&#x27;s important to note that I am not saying that the orientation and magnitude are useless it&#x27;s just that when trying to conceptualize what a bi Vector is by far the most important aspect is the two-dimensional Subspace it represents we can extend this idea by saying that vectors represent one-dimensional subspaces Tri vectors represent three-dimensional subspaces and in general K vectors represent K dimensional subspaces now it turns out that these correspondences have some exceptions but I&#x27;m not going to worry about that here anyway we can now build a multi-vector by adding several K vectors of different types together in many cases it can be useful to undo this sum which leads us to an important operation in geometric algebra the grade projection operator despite the fancy name the grade projection operator is quite simple it simply selects the K Vector part of a multi-vector and rewrite it with these angle brackets for example given a general multi-vector in 2D VGA we can find the scalar part the vector part and the bifector part using the great projection operator also as a shorthand we usually drop the subscript when writing the scalar part of a multi-vector thus when you see angle brackets without a subscript it means to take the scalar part of that multi-vector while the grade projection operator is simple it is surprisingly useful both in the development of the theory and in practice we will be using it many times throughout the rest of this video when a multi-vector only has a k Vector component we say that the multi-vector has a grade of K thus scalars are grade 0 objects vectors are grade 1 objects five vectors are grade two objects Etc now that we understand the basics of working with multi-vectors abstractly let&#x27;s move on to understanding the operations that we can do in geometric algebra we&#x27;ll start with the most fundamental operation of them all the geometric product there are many ways to think of the geometric product I will be exploring three here one that is geometric one that is algebraic and one that is related to transformations to understand the geometric picture let&#x27;s look at some examples in VGA first the product of two parallel vectors is simply the product of their lengths or the negative of that product if they&#x27;re facing in opposite directions If instead the two vectors are perpendicular the geometric product is the bi-vector spanned by the two vectors what these ideas show is that the geometric product contracts parallel directions and joins perpendicular directions now of course not everything that we want to multiply is either parallel or perpendicular to deal with this we use distributivity for example let&#x27;s say we wanted to multiply these two vectors to do this we can take this perpendicular line and then use it to split V into two parts one which is parallel to U and the other which is perpendicular to you at this point we can distribute now the first term is the product of two parallel vectors which is the product of their lengths and the second term is the product of two perpendicular vectors which is this bi-vector but this has all been VGA how do we multiply in other flavors well this way of thinking of the geometric product works in other flavors as long as you use the abstract definitions of parallel and perpendicular now what parallel and perpendicular look like geometrically will change depending on the flavor so you need to figure this out on a case-by-case basis however we can use this idea to develop the algebraic understanding of the geometric product let&#x27;s say that the space we are working in has an orthonormal basis given by vectors E1 E2 Etc because the basis is orthogonal we know that two different basis vectors are perpendicular so that when we multiply them we get the bifector that joins them together this operation of joining anti-commutes for vectors so the product of two different basis vectors anti-commutes now if we are multiplying a basis Vector with itself it is parallel with itself so the result will be a scalar because this is an orthonormal basis the result will be one or will it it is true that in VGA we want our vectors to square to their length squared however there are linear spaces where the concept of length doesn&#x27;t really apply and sometimes in those situations the closest thing that there is to length can have a negative value thus we want the square of our basis vectors to be able to be more values than one sometimes a basis Vector can square to negative one and there are even cases where basis Vector squares to zero for example in VGA every basis Vector squares to 1 euclidean PGA one basis Vector squares to zero while the rest Square to 1 and in CGA one basis Vector squares to negative one while the rest squared to positive one in general we could have any number of basis vectors squaring to one any number of basis vectors squaring to negative one and any number of basis vectors squaring to zero there&#x27;s a special notation that we use to signify this we use this notation to refer to a geometric algebra that has P basis vectors that square to 1 Q basis vectors that square to negative one and our basis vectors that square to zero another commonly used notation is CL which stands for Clifford the founder of geometric algebra because we know what the products of basis vectors are we can now use distributivity and associativity to calculate the product between arbitrary multivectors for example let&#x27;s say we&#x27;re working in g111 which means we have one basis Vector that squares to one one basis Vector that squares to negative one and one basis factor that squares to zero let&#x27;s calculate this product first we distribute next we start swapping products to get all of the same ones next to each other adding a minus sign with each swap now because E1 squares to 1 we can remove any factors of E1 squared because E2 squares to negative 1 we can remove it at the cost of a minus sign and because e0 squares to zero the last term disappears looking at this result I would like to introduce another bit of notation that can often make things more concise instead of writing say e0 E2 we instead write e02 in general we write e with several subscripts to represent the product of several basis vectors this notation can greatly reduce the number of E&#x27;s we have to write and it can be useful to be able to tell what kind of object something is by simply counting the number of subscripts now knowing how to calculate the geometric product is useless until we know why the geometric product itself is useful this leads us to the third view of the geometric product which is related to transformations in two-dimensional VGA we know that if we multiply a vector by two unit vectors the result is the vector rotated by the angle between the two unit vectors this is also the result you would get if you multiply the three vectors in the opposite direction this allows us to see that sandwiching one vector inside another unit Vector reflects that Vector across the unit vector if we do two Reflections we see that the result is the same as rotating a by twice the angle between V and U because multiplying a by v u on the right and by u v on the left both rotate a by that angle once now in higher Dimensions the simple rotation formula doesn&#x27;t hold but the reflection formula does hold because it only involves two vectors which means that they are in a two-dimensional Subspace speaking of Reflections we sometimes don&#x27;t want to reflect across a vector but instead reflected the vector itself to do this we need to add a minus sign we can compose Reflections together to create new Transformations and it turns out that you can get any orthogonal transformation this way perhaps surprisingly all of this generalizes almost perfectly to arbitrary flavors in two Dimensions the product of three vectors still represents a rotation and in any number of Dimensions the reflection formula still works which still allows you to create orthogonal Transformations through composition it&#x27;s important to realize that these are rotations and Reflections in the abstract sense you need to figure out exactly what they mean concretely on a case-by-case basis it turns out that there are many different kinds of Transformations that can be realized as orthogonal transformations in some geometric algebra in general the geometric product is useful for its ability to represent compose and apply orthogonal transformations now I want to focus a bit more on this expression here notice that on one side we have the product of several vectors while on the other side we have the same product but in reverse this idea leads us to the next operation I want to discuss the reverse the reverse takes a product and well reverses it the notation that we will use for this operation is this dagger symbol placed after the thing we want to reverse however there are actually many different notations that people use for the reverse the two that are used the most are the dagger and putting a tilde on top of what we are reversing however I think the tilde looks strange when finding the reverse of the product of several variables some people put the tilde after everything in this case but it still looks weird to me thus I will be using the dagger for the reverse because this operation is actually similar to The Complex conjugate I have used a star in the past for the reverse however the star is usually used for other operations in geometric algebra so I&#x27;ll use the dagger for the reverse from now on surprisingly the reverse can be made into a linear function which allows us to calculate the reverse of an arbitrary multi-vector to calculate the reverse here we first use linearity to distribute the reverse allowing us to compute the reverse of each term separately now because scalars have no Vector factors the reverse doesn&#x27;t affect scalars meaning that the reverse of 1 is 1. similarly reversing the order of one vector doesn&#x27;t do anything so the reverse of E1 is E1 for the rest of the terms we just need to reverse the order of the products while this result is correct it&#x27;s often nicer to get the subscript sorted again we can do this by swapping and adding minus signs because we are working in an orthonormal basis comparing this with the original multi-vector that we reversed we see that the only thing the reverse ended up doing was changing the signs of the bifector and trivector part it&#x27;s not too difficult to prove that in general the sign of the reverse swaps every two grades this property of the reverse makes it incredibly easy to calculate in addition to it being useful theoretically as a way to reverse products now it turns out that there&#x27;s another operation that&#x27;s similar to the reverse in that it only flips the signs of certain grades except that instead of switching every two grades we switch every grade we give this operation the fancy name grade involution like the reverse it seems that nobody can agree on what notation to use for the great involution the two most common notations are putting a star after what we are involuting or putting a hat over what we are involuting using the star can get confusing because some people represent the Dual in geometric algebra with a star as well however the Hat has the same issue because we already use the hat to represent unit vectors so we&#x27;ll have to deal with this confusion either way I don&#x27;t like the look of the hat for the same reasons as before so I prefer using the star I&#x27;ll be covering the Dual in more detail later and at that point I&#x27;ll introduce a slightly different notation for it now the great involution is perhaps surprisingly both linear and multiplicative making it easy to work with as a quick example here is the great involution of the multi-vector we were looking at before both the reverse and the grade involution are useful algebraic tools and they pop up in many equations now the next thing I want to talk about is the magnitude of a multi-vector we already know how to calculate the magnitude of scalars and vectors but what about the magnitude of an arbitrary multivector let&#x27;s think about how we find the magnitude of scalars and vectors in VGA the magnitude of a vector can be calculated as the square root of the square of the vector if we wanted to we could calculate the absolute value of a scalar in the same way this gives us our first idea for a definition of the absolute value of a multivector however this definition has several issues the first issue is that in some flavors of geometric algebra vectors can square to negative values making the square root on the right not defined thus instead of talking about the magnitude of a multi-vector we will only talk about the magnitude squared of a multi-vector talking about the magnitude squared without defining the magnitude itself may seem strange but it turns out that in many of the cases that you want the magnitude what you really want is the magnitude squared anyway however this definition for the magnitude squared still doesn&#x27;t work for example consider the bi-vector E12 in VGA we would want the magnitude of a bi-vector in VGA to be its area so in this case the magnitude squared should be one however E12 squared is negative one not one the issue is that when squaring E12 you have to swap a product and doing so creates the minus sign well if the problem is that we get minus signs from swapping why not instead Define the magnitude squared to have all the swapping done before multiplying to be more concrete instead of just squaring the multi-vector we can multiply the multi-vector by its reverse the reverse doesn&#x27;t affect scalars and vectors so this definition still works for them now for E12 when we multiply it by its reverse everything works out to make the result one like we wanted at this point our definition of the magnitude squared is almost perfect however there is still one more issue with it consider the magnitude squared of a mixed grade multivector such as 1 plus E1 when you calculate it with this formula it turns out that the result is 2 plus 2 times E1 but wait that&#x27;s not a scalar shouldn&#x27;t the magnitude always be a scalar the way we solve this problem may seem a little silly we just take the scalar part of the multi-vector times its reverse doing this will trivially make the result always a scalar one interesting fact about this definition for the magnitude squared is that it might be more similar to the magnitude squared of a vector than you might think for example if you compute the magnitude squared of an arbitrary 2D multi-vector in VGA the result is simply the sum of the components squared just like for vectors this result holds in all dimensions for VGA and in other flavors similar results hold with only a few sign changes in general this is the way we compute magnitudes in geometric algebra let&#x27;s now move on to exploring some of the other products that are present in geometric algebra starting with the outer product going back to VGA for the moment we know that the outer product of these two vectors is this bi-vector how can we generalize this to other flavors of geometric algebra well remember that bi-vectors represent two-dimensional subspaces in this case the bifector represents the whole plane now notice that this plane is the span of the two vectors that we started with if you think about it even in higher Dimensions this should always be the case thus the outer product of two vectors represents their span this result generalizes to the outer product of any number of vectors the outer product of any number of vectors represents their span however there is actually one major issue with this idea we know that the outer product of a vector with itself is zero the problem here is that the span of a vector with itself is one dimensional not two-dimensional the outer product of two vectors must be a bi-vector so if the two vectors don&#x27;t form a two-dimensional Subspace the outer product can&#x27;t result in the span of the vectors in the end the only bi-vector contained in their span is zero so the outer product is zero for the several Vector case the outer product of n vectors can only be their span if the span is n-dimensional this condition is equivalent to the vectors being linearly independent thus we see that the outer product of linearly independent vectors represents their span if the vectors are linearly dependent then the outer product is zero now this is all well and good but how do we actually calculate the outer product algebraically there are two main ways of calculating it the first is to recognize that the equations that the outer product satisfies for vectors looks suspiciously like the equations for the geometric product in fact we can think of the outer product as simply being the geometric product in the situation where all the vectors Square to zero this makes calculating the outer product very simple here&#x27;s an example like with any product we start with Distributing at this point we see that both parts of the first term have a factor of E1 so the first term is zero similarly in the last term both parts have factors of E5 and E6 so the last term is zero as well in the remaining terms because the parts don&#x27;t share any factors the outer product is the same as the geometric product I like to have my basis multi-vector sorted which ends up producing this result comparing this to the original expression you might realize that here the outer product of a two vector and a four Vector is a six vector this holds in general with the outer product of a j vector and a k Vector always being a j plus K vector in fact this can lead us to the other way of calculating the outer product If instead of calculating the outer product of these two multi-vectors we calculate their geometric product saying VGA this is the result we see that the geometric product gets split up into a two Vector 4 vector and six Vector part we also see that the six Vector part of the geometric product is precisely the outer product of the two multi vectors when you think about it this should make sense when there are no common factors the geometric and outer products are identical and when there are common factors they contract to produce a lower grade result thus we can calculate the outer product of a j vector and a k vector by calculating their geometric product and then taking the J plus K grade part of the result while this way of computing the outer product may not be as efficient as the previous way it can be useful in theoretical contexts now the next operation I want to talk about is one that I haven&#x27;t ever mentioned on this channel before remember that geometrically the outer product represents the span we can think of the span as being the smallest Subspace containing the inputs there&#x27;s a sort of dual notion to this idea where instead of thinking of the smallest Subspace containing the inputs we think of the largest Subspace contained in the inputs formalizing this idea leads us to a new product which an abstract context is called the regressive product because the regressive product can be thought of as the Dual version of the outer product we write the regressive product with a V symbol which is similar to the symbol we use for the outer product of course we still have no idea how to actually calculate the regressive product to move towards this let&#x27;s look at an example in 3D VGA consider these two bi-vectors which are e13 and e32 what is their regressive product well if we think of the subspaces that these bi-vectors represent we can see that the largest Subspace contained by both of them is this vertical line going along their intersection and here we&#x27;re faced with a problem the answer is a vector in this line but which Vector is it the issue is that just saying that the regressive product is the largest Subspace contained in the inputs doesn&#x27;t tell us what the orientation or magnitude of the result is thus the regressive product is currently not completely defined let&#x27;s take a step back and think about this a little more notice that because the Subspace represented by the regressive product is a Subspace of the inputs everything that is perpendicular to one of the inputs is also perpendicular to the regressive product I mentioned in my Swift introduction to geometric algebra that we can find the object perpendicular to another one with the Dual which we calculate by multiplying the object by the unit pseudoscaler which in this case is e123 in fact these two vectors here are e32 times I and e13 times I and while we don&#x27;t know exactly what Vector the regressive product is here we can at least know that its duo will be represented by the plane that&#x27;s perpendicular to this line wait a minute this plane is the same as the one created by the outer product of the duals of the inputs what we see is that in this case the Dual of the regressive product is equal to the outer product of the duals thus we use this equation to exactly Define the regressive product for arbitrary inputs using this formula we can finally figure out what the regressive product of e13 and e32 actually is first we need to calculate the Dual of e13 and e32 which are just E2 and E1 at the outer product of E2 and E1 is just E21 and the inverse dual of E21 is negative E3 now there are two important things I need to say about this equation the first thing is that this definition doesn&#x27;t actually always correspond to the geometric operation that we originally described for example while the previous three-dimensional example works as we wanted it to if we calculate the same thing in four dimensions the result actually turns out to be zero the reason for this is that the outer product doesn&#x27;t always calculate the span as we mentioned earlier because we defined the regressive product in terms of the outer product it inherited this quirk however as long as we are sure that the duals of our inputs are linearly independent the regressive product works just fine now the other thing I want to mention about this equation is the way that we calculate the Dual I&#x27;ve mentioned before on this channel that we calculate the Dual by multiplying by I and we can reverse the process by multiplying by the inverse of I but does this work in all contexts the answer is perhaps surprisingly no thus let&#x27;s move on to looking at the Dual in geometric algebra in closer detail the fundamental idea behind the Dual is that it represents the orthogonal complement of an object for example in three dimensions the object that is perpendicular to E1 is e23 however negative e23 also represents the orthogonal complement to E1 so which one is it well it turns out that both of these answers can work interestingly whenever using the Dual you usually combine it with the inverse operation somewhere else which means that any difference is in sign between definitions of the Dual will cancel each other out the easiest way to Define duality is by multiplying by the unit pseudoscaler this works because the geometric product contracts parallel Parts leaving only the perpendicular Parts which is the orthogonal complement so what&#x27;s wrong with this definition the issue appears when you are working in a geometric algebra where some of the basis vectors Square to zero consider a two-dimensional algebra with a basis Vector that squares to zero then if we try to find the Dual of e0 the result ends up being zero this isn&#x27;t the orthogonal complement of e0 and furthermore this result implies that multiplication by I is no longer invertible thus in situations where a basis Vector squares to zero multiplication by I is no longer a good definition of Duality so we need to come up with something else the definition of Duality I&#x27;m about to describe is basically something called the Hodge star so I&#x27;ll use the notation for it here where we use a star before something to represent its dual we&#x27;ll use the incorrect pseudoscalar definition of the Dual as our starting point into looking for a better definition if the problem arises because of the multiplication between a and I why not just move a to the other side of the equation now on the left we will be multiplying an object by its orthogonal complement so there are no parallel directions to square to zero anymore but now the magnitudes don&#x27;t work out quite right we could say that the result has to be the magnitude of a squared times I but when the magnitude of a is zero this implies that the Dual of something non-zero can be zero again which we don&#x27;t want for the same reasons as before we could say that this definition only works when a is normalized but if a squares to zero there&#x27;s no way to normalize it so that won&#x27;t work either instead to make this work I&#x27;ll forget about trying to Define this elegantly in a basis independent way and invoke a particular orthonormal basis for example let&#x27;s say we are working in a two-dimensional algebra with basis vectors E1 and E2 then our basis multi vectors are one E1 E2 and E12 for each of these basis multi-vectors we want the product of it with its dual to be the unit pseudoscaler which I&#x27;ll write out as E12 here from these equations we can see what the Dual of each basis multi-vector is from knowing the Dual of the basis multi-vectors we can extend bilinearity to define the Dual of all multi-vectors even though this definition isn&#x27;t elegant it does work also in the situations that we care about all the problems that arise from the fact that this definition is unnatural go away when we calculate the inverse of the Dual using this definition of Duality we can rewrite the formula for the regressive products like this where we write star inverse for the inverse of the Dual we can always calculate the regressive product using this formula no matter what flavor of geometric algebra we are working in now the last operation I want to talk about is the inner product to be honest I&#x27;ve put off talking about the inner product in detail on this channel because of all of the problems that arise but I&#x27;ll deal with those problems now before I get into it I have to mention that calling this operation that I&#x27;m about to describe the inner product is a bit of a misnomer traditionally the term inner product refers to a function that is bilinear produces a scalar is symmetric and is positive definite however while the inner product in geometric algebra is bilinear it produces multi-vectors not scalars it is not symmetric and even when the inner product of something with itself is a scalar it can be negative however despite these differences the inner product in geometric algebra is a generalization of the traditional inner product in a geometric sense let&#x27;s look into the inner products between two vectors in Greater detail to see how to extend it to all multi-vectors like usual let&#x27;s start by looking at VGA we calculate the inner products by projecting one vector onto the other one and then calculating the product of their lengths in geometric algebra finding the product of the lengths of two parallel vectors is easy it&#x27;s just the product of the two vectors themselves thus we can think of the inner product as being a projection and then a multiplication actually we can go one step further after projecting both objects will be completely parallel the result of multiplying parallel objects is a contraction so we can instead think of the inner product as being a projection and then a contraction this idea of projection and contraction is the fundamental geometric idea that we will use to generalize the inner product to arbitrary multi-vectors for example let&#x27;s try to calculate the inner product of this bi-vector with this vector to do this we first project the vector onto the bi-vector now the direction of the vector contracts with the part of the bi-vector that points in the same direction leaving just a vector that points in a direction perpendicular to the original but still in the plane of the bi-vector now there is one glaring issue that arises as we try to become more precise with this idea that causes a lot of problems let&#x27;s consider an arbitrary inner product with two multi-vectors A and B this means that we project a onto b or is it B onto a with vectors this doesn&#x27;t matter but when we start mixing grades things get more complicated let&#x27;s say a was a vector and B was a bi-vector in our previous example we projected the vector onto the bi-vector and everything seemed good but what about projecting the bifector onto the vector that just seems strange there are different ways to resolve this issue and they lead to similar but slightly different definitions of the inner product the first way to resolve it is to say that we always project the first argument onto the second defining the inner product this way produces an operation called the left contraction denoted with this vertical bar with a thing sticking out to the left if the greater of the first argument is greater than the grade of the second argument we just give up on doing the projection and say that the result is zero we could also say that we always project the second argument onto the first this produces the right contraction which is in some sense a symmetric version of the left contraction if the second argument has a higher grade than the first we again give up and say that the result is zero the last version is to just pick whichever argument has the lower grade and then project from that one onto the other one this produces an operation that we usually just call the inner product if a and b have the same grade these three operations will produce the same result for mixed grades they will each do something a little different for example let&#x27;s say that we have a vector a and a bi-vector b and let a parallel be the projection of a onto B then the left contraction of A and B is a parallel times B the right contraction of A and B is 0 because the grade of B is greater than the grade of a and the inner product of A and B is also a parallel times B we can also try swapping the arguments the left contraction of b and a is zero because the grade of B is greater than the grade of a the right contraction of b and a is B times a parallel and the inner product of b and a is also B times a parallel before we move on I want to mention that this idea of projection and contraction actually works in all flavors things like projections can be considered abstractly so we can still think of the inner products in this way now the next question we need to ask is how do we actually calculate these products to figure this out let&#x27;s try to calculate this inner product like usual we start with Distributing now the second and third terms have no factors in common meaning that they are completely perpendicular thus projecting one onto the other produces zero meaning that their inner product is zero now in the last term here e56 is already entirely in e3456 meaning that projecting e56 onto e3456 does nothing so the inner product there is just the geometric product let&#x27;s assume that we&#x27;re working in VGA then this product is negative E34 now the first term is a bit more complicated while the two parts have a common factor of E1 e0 is in the first part but not in the second part in the end because e0 is in the first part but not the second part e01 is perpendicular to e1234 so the projection and thus the inner product is zero comparing this to the outer product we see that the outer product of two bases multi vectors is their geometric product if they share No factors while the inner product of two basis multi-vectors is their geometric product if they share all factors it&#x27;s the same thing for the left and right contractions except that you also have to check the grade of all the objects involved now the next thing I want to talk about is how these different inner products interact with the grade of their arguments with the outer product the outer product of a j vector and a k Vector is the J plus K grade part of their geometric product it turns out that there are similar equations for the different inner products for the left contraction we project the first argument onto the second argument and then contract thus the grade of the result will start out as the grade of the second argument but then the contraction will subtract off the grade of the first argument notice that if the grade of the first argument is greater than the grade of the second one we will be calculating the grade projection with a negative grade there is no such thing as a negative grade so we just say that the result is zero which is what we would expect with the left contraction of a higher grade object onto a lower grade object for the right contraction the same argument Works to show that the grade of the result is the grade of the first argument minus the grade of the second argument as for the inner product we pick whichever of the two differences is positive which we can do with an absolute value When developing the theory of geometric algebra it turns out that these equations are usually taken to be the definitions of these operations looking at these equations we can see why the inner product is harder to Define than the outer product addition is commutative while subtraction is not which causes there to be multiple distinct ways to define the inner product now a natural question that arises from having several different inner products is when do we use the different inner products in my experience whenever you are working in some particular application using the inner product which is the one that automatically projects the lower grade object onto the higher grade object is the simplest option to use in applications we tend to know the grade of all the objects involved so having to be careful with Which object we are projecting onto is not really an issue that we need or want to care about however when working theoretically the left and right contractions tend to be much more important many General equations involving the inner product are only true when we use the contractions which makes them more useful in theoretical contexts the classic example in this regard is the fact that while the geometric product of a vector and a multi-vector is not the sum of their inner and outer products it is true that it is the sum of the left contraction and the outer product now you need to be careful because it&#x27;s still not the case that the geometric products are two arbitrary multi-vectors is the sum of their left contraction and their outer product this equation is only true if a is a vector while these guidelines might not always work they should be a good rule of thumb for figuring out which inner product you want to use we have now covered all of the operations that I wanted to go through in this video you should now be able to describe any of these operations at least on a basic level there are other operations in geometric algebra such as the scalar product the commutator product and the Clifford conjugate But I either thought they weren&#x27;t important enough or I didn&#x27;t understand them well enough to be included in this video I hope that this video has expanded your horizons and has enabled you to explore the other flavors of geometric algebra</p>
        </div>
    </article>

    <footer>
        <p><a href="../index.html">&larr; Back to index</a></p>
    </footer>
</body>
</html>